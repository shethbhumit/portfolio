# Portfolio
---
## Supply Chain Analytics 

### <ins>Master's Capstone Project</ins>: *"Predicting Shipping Time/Transit Time to show ​ETA/ETD for shipments using Machine Learning models"* <br>

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/algonauts2023-image-fMRI-encoding-model)
[![Open PDF](https://img.shields.io/badge/PDF-Read%20Thesis%20PDF-red?logo=adobe-acrobat-reader)](https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing)
[![Open PDF](https://img.shields.io/badge/PDF-View%20Slides%20PDF-red?logo=adobe-acrobat-reader)](https://www.slideshare.net/slideshow/masters-thesis-data-science-presentation/266926165)


_Key Skills: Python (PyTorch, scikit-learn), Visual Encoding Model, Image-fMRI Encoding, Computational Neuroscience, Artificial Vision_

<div style="text-align: justify">
During a <b>research internship</b> at the <b>Imaging and Vision Laboratory</b> at the <b>University of Milano-Bicocca</b> I worked on my <b>master's thesis</b> “Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”, which I developed by competing in the "<b>Algonauts Project 2023 Challenge</b>: How the
Human Brain Makes Sense of Natural Scenes", exploring the interdisciplinary research related to one of the unsolved problems in both neuroscience and artificial intelligence: the ability to perceive and understand complex natural scenes.
<br>
The main objective of the thesis was to develop a comprehensive <b>voxel-based and subject-specific image-fMRI neural encoding model of the human visual cortex based on Deep Neural Networks (DNNs) and transfer learning</b> for the prediction of local neural blood oxygen level-dependent (BOLD) functional magnetic resonance imaging (fMRI) responses to complex visual stimuli.
The results of my study are collected in my <b>Master's thesis</b>: <a href="https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing">“Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”</a> <br>

</div>
<br>
<center><img src="images/visualencoding.png"/></center>
<br>

---

### Sustainability Metrics: Offering Insights into Decision-Making Parameters

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/algonauts2023-image-fMRI-encoding-model)
[![Open PDF](https://img.shields.io/badge/PDF-Read%20Thesis%20PDF-red?logo=adobe-acrobat-reader)](https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing)
[![Open PDF](https://img.shields.io/badge/PDF-View%20Slides%20PDF-red?logo=adobe-acrobat-reader)](https://www.slideshare.net/slideshow/masters-thesis-data-science-presentation/266926165)


_Key Skills: Python (PyTorch, scikit-learn), Visual Encoding Model, Image-fMRI Encoding, Computational Neuroscience, Artificial Vision_

<div style="text-align: justify">
During a <b>research internship</b> at the <b>Imaging and Vision Laboratory</b> at the <b>University of Milano-Bicocca</b> I worked on my <b>master's thesis</b> “Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”, which I developed by competing in the "<b>Algonauts Project 2023 Challenge</b>: How the
Human Brain Makes Sense of Natural Scenes", exploring the interdisciplinary research related to one of the unsolved problems in both neuroscience and artificial intelligence: the ability to perceive and understand complex natural scenes.
<br>
The main objective of the thesis was to develop a comprehensive <b>voxel-based and subject-specific image-fMRI neural encoding model of the human visual cortex based on Deep Neural Networks (DNNs) and transfer learning</b> for the prediction of local neural blood oxygen level-dependent (BOLD) functional magnetic resonance imaging (fMRI) responses to complex visual stimuli.
The results of my study are collected in my <b>Master's thesis</b>: <a href="https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing">“Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”</a> <br>

</div>
<br>
<center><img src="images/visualencoding.png"/></center>
<br>

---

## Deep Learning/ LLM 

### NewsPulse AI: User-frinedly News Research Tool

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/shethbhumit/NewsPulse-AI)
<!-- [![Open PDF](https://img.shields.io/badge/PDF-Read%20Thesis%20PDF-red?logo=adobe-acrobat-reader)](https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing) -->

_Key Skills: Python (PyTorch, scikit-learn), Visual Encoding Model, Image-fMRI Encoding, Computational Neuroscience, Artificial Vision_

<div style="text-align: justify">
During a <b>research internship</b> at the <b>Imaging and Vision Laboratory</b> at the <b>University of Milano-Bicocca</b> I worked on my <b>master's thesis</b> “Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”, which I developed by competing in the "<b>Algonauts Project 2023 Challenge</b>: How the
Human Brain Makes Sense of Natural Scenes", exploring the interdisciplinary research related to one of the unsolved problems in both neuroscience and artificial intelligence: the ability to perceive and understand complex natural scenes.
<br>
The main objective of the thesis was to develop a comprehensive <b>voxel-based and subject-specific image-fMRI neural encoding model of the human visual cortex based on Deep Neural Networks (DNNs) and transfer learning</b> for the prediction of local neural blood oxygen level-dependent (BOLD) functional magnetic resonance imaging (fMRI) responses to complex visual stimuli.
The results of my study are collected in my <b>Master's thesis</b>: <a href="https://drive.google.com/file/d/1hf3gs0VAdlfDIobfEtqeOhS8HHD0UfpI/view?usp=sharing">“Deep Neural Encoding Models of the Human Visual Cortex to Predict fMRI Responses to Natural Visual Scenes”</a> <br>

</div>
<br>
<center><img src="images/NewsPulse.jpg"/></center>
<br>
---

## Machine Learning

### Fraud Detection Using Predictive Analytics

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection)
[![KNIME Hub Workflow](https://img.shields.io/badge/KNIME-View%20on%20KNIME%20HUB-yellow?logo=Knime)](https://kni.me/w/c2_iSRBcc1v7b6pUn)
[![Project Report](https://img.shields.io/badge/PDF-Read%20Report%20PDF-red?logo=adobe-acrobat-reader&logoColor=white)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection/blob/main/Project_Report.pdf)

_Key Skills: KNIME, Classification, Fraud Detection, Random Forest, Support Vector Machine, Naive Bayes, Logistic Regression_

<div style="text-align: justify">
The project consists in the application of <b>different classification models</b> to a dataset containing data relating to <b>credit card transactions</b> for the <b>detection of financial fraud</b>.
<br> <br>
One of the most critical processes in finance is the <b>detection of fraudulent credit card transactions</b>. 
In the first part of the project, we compared different techniques to counter the presence of <b>unbalanced classes</b> within the dataset. Then we <b>compared the performance</b> of some of the most widely used <b>classification algorithms</b> in this area. To determine the best method, we did not limit ourselves to the usual metrics but also took into account the costs to the financial institution related to any errors the model may make, a key aspect in this area.
</div>
<br>
<center><img src="images/MLKnime.png"/></center>
<br>

---
### Santander Customer Satisfaction: A Kaggle Competition

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection)
[![KNIME Hub Workflow](https://img.shields.io/badge/KNIME-View%20on%20KNIME%20HUB-yellow?logo=Knime)](https://kni.me/w/c2_iSRBcc1v7b6pUn)
[![Project Report](https://img.shields.io/badge/PDF-Read%20Report%20PDF-red?logo=adobe-acrobat-reader&logoColor=white)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection/blob/main/Project_Report.pdf)

_Key Skills: KNIME, Classification, Fraud Detection, Random Forest, Support Vector Machine, Naive Bayes, Logistic Regression_

<div style="text-align: justify">
The project consists in the application of <b>different classification models</b> to a dataset containing data relating to <b>credit card transactions</b> for the <b>detection of financial fraud</b>.
<br> <br>
One of the most critical processes in finance is the <b>detection of fraudulent credit card transactions</b>. 
In the first part of the project, we compared different techniques to counter the presence of <b>unbalanced classes</b> within the dataset. Then we <b>compared the performance</b> of some of the most widely used <b>classification algorithms</b> in this area. To determine the best method, we did not limit ourselves to the usual metrics but also took into account the costs to the financial institution related to any errors the model may make, a key aspect in this area.
</div>
<br>
<center><img src="images/MLKnime.png"/></center>
<br>

---
### Homesite Quote Conversion

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection)
[![KNIME Hub Workflow](https://img.shields.io/badge/KNIME-View%20on%20KNIME%20HUB-yellow?logo=Knime)](https://kni.me/w/c2_iSRBcc1v7b6pUn)
[![Project Report](https://img.shields.io/badge/PDF-Read%20Report%20PDF-red?logo=adobe-acrobat-reader&logoColor=white)](https://github.com/giocoal/Knime_Classification_Credit-Card-Fraud-Decection/blob/main/Project_Report.pdf)

_Key Skills: KNIME, Classification, Fraud Detection, Random Forest, Support Vector Machine, Naive Bayes, Logistic Regression_

<div style="text-align: justify">
The project consists in the application of <b>different classification models</b> to a dataset containing data relating to <b>credit card transactions</b> for the <b>detection of financial fraud</b>.
<br> <br>
One of the most critical processes in finance is the <b>detection of fraudulent credit card transactions</b>. 
In the first part of the project, we compared different techniques to counter the presence of <b>unbalanced classes</b> within the dataset. Then we <b>compared the performance</b> of some of the most widely used <b>classification algorithms</b> in this area. To determine the best method, we did not limit ourselves to the usual metrics but also took into account the costs to the financial institution related to any errors the model may make, a key aspect in this area.
</div>
<br>
<center><img src="images/MLKnime.png"/></center>
<br>

---

## Natural Language Processing

### Word Embedding (Word2Vec and CADE): the Evolution of Tópoi in the Italian Literary Tradition

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/word-embedding-italian-literature)
[![Open PDF](https://img.shields.io/badge/PDF-View%20Slides%20PDF-red?logo=adobe-acrobat-reader)](https://github.com/giocoal/word-embedding-italian-literature/blob/main/Project%20Report%20EN.pdf)

_Key Skills: Python (gensim, spaCy, NLTK, Word2Vec), Distibuctional Semantics, Literary Corpuses_

<div style="text-align: justify">
Using <b>distibuctional semantics</b> (<b>word2vec</b> family algorithms and the <b>CADE</b> framework) to learn <b>word embeddings</b> from the <b>Italian</b> literary corpuses we generated.
<br> <br>
The <b>goals</b> of our project were: 
<br>
<b>1.</b> to <b>obtain corpora</b> that were consistent with our research questions from a collection of texts obtained from two main sources; 
<br>
<b>2.</b> to use distibutional semantics, and in particular algorithms from the word2vec family, along with the CADE framework, in order to learn <b>word embeddings</b> from the generated and processed corpora;
<br>
<b>3.</b> and finally to <b>analyze</b> some particularly <b>long-lived tòpos</b>, chosen arbitrarily, to be able to answer some research questions.
</div>
<br>
<center><img src="images/DataSemanticsItalianLiterature.jpg"/></center>
<br>

---
## Data Visualization

### AIRBNB Review Analytics: Exploring Amsterdam's Hosting Landscape

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/Air_Pollution_Data_Visualization_Tableau)
[![View on Tableau](https://img.shields.io/badge/Tableau-View_on_Tableau-orange?logo=Tableau)](https://public.tableau.com/app/profile/giorgio.carbone3907/viz/IndicediQualitdellAriaIQAnellagglomeratodiMilanoanalisidellandamentostagionaleeannualeCarboneCavallaroMarconziniScuri/Dashboard_HOME)
[![Open PDF](https://img.shields.io/badge/PDF-View%20Slides%20PDF-red?logo=adobe-acrobat-reader)](https://github.com/giocoal/Air_Pollution_Data_Visualization_Tableau/blob/main/Report/CarboneCavallaroMarconziniScuri.pdf)

_Key Skills: Tableau, Interactive Visualization, Air Quality Data Analysis_

<div style="text-align: justify">Has <b>air quality</b> improved over the past 15 years in and around <b>Milan</b>? Is the concentration of pollutants higher in winter or summer? and why? What are the main pollutants, and what meteorological and anthropogenic factors influence the seasonal pattern of their concentrations?
<br>
We tried to answer these, and other, questions by analyzing data from ARPA Lombardy. The results of our analysis were then displayed in an <b>interactive infographic</b> created using the <b>Tableau</b> platform.
</div>
<br>
<center><img src="images/ARPAVIZ.gif"/></center>
<br>

---
## People Analytics

### IOWA Business Analytics Case Competition: Ball Corporation Organizational Health

[![View on GitHub](https://img.shields.io/badge/GitHub-View_on_GitHub-blue?logo=GitHub)](https://github.com/giocoal/Competitive-Pokemon-Graph-Database)
[![View on Neo4j](https://img.shields.io/badge/Neo4J-View_on_Neo4J-lightgrey?logo=Neo4j)]()
[![View on Kaggle](https://img.shields.io/badge/Kaggle-View_on_Kaggle-blue?logo=Kaggle)](https://www.kaggle.com/datasets/giorgiocarbone/complete-competitive-pokmon-datasets-may-2022)
[![Open PDF](https://img.shields.io/badge/PDF-Read%20%20Report%20%20PDF-red?logo=adobe-acrobat-reader)](https://github.com/giocoal/Competitive-Pokemon-Graph-Database/blob/main/Project%20Report.pdf)
[![Open PDF](https://img.shields.io/badge/PDF-View%20%20Slides%20%20PDF-red?logo=adobe-acrobat-reader)](https://github.com/giocoal/competitive-pokemon-graph-database/blob/main/Project%20Slides.pdf)

_Key Skills: Python (Beautiful Soup, Scrapy, Selenium, Request), Neo4j, Data Acquisition, API, Web Scraping, Data Integration, Data Modeling, Graph Database_

<div style="text-align: justify">
Data Acquisition and Modeling: <b>Graph database</b> containing information related to <b>competitive Pokémon videogames</b>, <b>scraped</b> from various sources
<br> <br>
The idea behind the project is to create a <b>graph database</b> containing information related to the <b>competitive Pokémon videogame</b>, with particular reference to the Video Game Championship Series 12 rules, the official format in effect for official tournaments and events during the period February - August 2022 and valid for the Pokémon World Championship in London in August 2022. The goal is to obtain a useful <b>tool as a support for competitive play</b>, both for novice and experienced players. The different <b>Pokémon are placed in relation to the teammates, moves, tools and the basic statistics with which they are most frequently matched</b> within teams in competitive matches. For this reason, the choice on the type of database to be implemented fell on a graph database, implemented through <b>Neo4J</b>. The choice of the graph database allowed us to take advantage of its characteristic of being schema less, which allows us to create nodes, to model the different entities, and arcs, to model the various relationships, without following a predefined schema. The database was populated through data obtained through <b>API</b> and <b>Web Scraping</b>, appropriately integrated and processed.
</div>
<br>
<center><img src="images/DataManagementProject.jpg"/></center>
<br>

<center>© 2024 Bhumit Sheth. </center>